{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CSC14120 - Parallel Programming Final Project\n",
                "# Autoencoder-based Feature Learning for CIFAR-10 Classification\n",
                "\n",
                "---\n",
                "\n",
                "**Team:** Team 18\n",
                "\n",
                "**Video Presentation:** [YouTube Link - Unlisted]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 1: Problem Description\n",
                "\n",
                "## 1.1 Problem Statement\n",
                "\n",
                "Unsupervised feature learning using Autoencoder for CIFAR-10 image classification with GPU acceleration.\n",
                "\n",
                "| Stage | Description | Output |\n",
                "|-------|-------------|--------|\n",
                "| Stage 1 | Train Autoencoder (unsupervised) | 8,192-dim features |\n",
                "| Stage 2 | Train SVM on extracted features | 10-class classification |\n",
                "\n",
                "**Motivation:** CPU training takes hours due to compute-intensive convolution operations. GPU parallelization targets <10 minute training with >20x speedup.\n",
                "\n",
                "## 1.2 CIFAR-10 Dataset\n",
                "\n",
                "| Specification | Value |\n",
                "|---------------|-------|\n",
                "| Image size | 32x32x3 (RGB) |\n",
                "| Training set | 50,000 images |\n",
                "| Test set | 10,000 images |\n",
                "| Classes | 10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) |\n",
                "| Data format | Binary files, uint8 pixels normalized to [0,1] |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup: Clone repository and download dataset\n",
                "import os\n",
                "\n",
                "repos = \"https://github.com/QuackPhuc/AutoEncoder-CUDA.git\"\n",
                "\n",
                "if not os.path.exists('/content/AutoEncoder-CUDA'):\n",
                "    !git clone --recursive {repos}\n",
                "\n",
                "%cd /content/AutoEncoder-CUDA\n",
                "!chmod +x scripts/*.sh build.sh run.sh\n",
                "!scripts/download_cifar10.sh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset samples visualization\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "def load_cifar10_batch(file_path):\n",
                "    with open(file_path, 'rb') as f:\n",
                "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
                "    data = data.reshape(-1, 3073)\n",
                "    labels = data[:, 0]\n",
                "    images = data[:, 1:].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
                "    return images, labels\n",
                "\n",
                "images, labels = load_cifar10_batch('/content/AutoEncoder-CUDA/data/data_batch_1.bin')\n",
                "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
                "\n",
                "fig, axes = plt.subplots(2, 10, figsize=(14, 3))\n",
                "fig.suptitle('CIFAR-10 Dataset Samples', fontsize=11, fontweight='bold')\n",
                "for class_idx in range(10):\n",
                "    class_images = images[labels == class_idx]\n",
                "    for row in range(2):\n",
                "        ax = axes[row, class_idx]\n",
                "        ax.imshow(class_images[row])\n",
                "        ax.axis('off')\n",
                "        if row == 0:\n",
                "            ax.set_title(class_names[class_idx], fontsize=8)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.3 Autoencoder Architecture\n",
                "\n",
                "```text\n",
                "INPUT (32x32x3)\n",
                "    |\n",
                "[ENCODER]\n",
                "    Conv2D(256, 3x3, pad=1) + ReLU -> (32x32x256)   # 7,168 params\n",
                "    MaxPool2D(2x2)                 -> (16x16x256)\n",
                "    Conv2D(128, 3x3, pad=1) + ReLU -> (16x16x128)   # 295,040 params\n",
                "    MaxPool2D(2x2)                 -> (8x8x128)\n",
                "    |\n",
                "LATENT REPRESENTATION (8x8x128 = 8,192 dimensions)\n",
                "    |\n",
                "[DECODER]\n",
                "    Conv2D(128, 3x3, pad=1) + ReLU -> (8x8x128)     # 147,584 params\n",
                "    Upsample2D(2x2)                -> (16x16x128)\n",
                "    Conv2D(256, 3x3, pad=1) + ReLU -> (16x16x256)   # 295,168 params\n",
                "    Upsample2D(2x2)                -> (32x32x256)\n",
                "    Conv2D(3, 3x3, pad=1)          -> (32x32x3)     # 6,915 params\n",
                "    |\n",
                "OUTPUT (32x32x3)\n",
                "```\n",
                "\n",
                "**Total Parameters:** 751,875 (all trainable)\n",
                "\n",
                "## 1.4 Performance Targets\n",
                "\n",
                "| Metric | Target |\n",
                "|--------|--------|\n",
                "| Autoencoder training time | < 10 minutes |\n",
                "| Feature extraction time | < 20 seconds (60K images) |\n",
                "| Test classification accuracy | 60-65% |\n",
                "| GPU speedup over CPU | > 20x |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 2: Implementation Phases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build project\n",
                "%cd /content/AutoEncoder-CUDA\n",
                "!./build.sh --clean"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.1: CPU Baseline\n",
                "\n",
                "**Objective:** Implement complete autoencoder on CPU to establish performance baseline.\n",
                "\n",
                "**Implementation Details:**\n",
                "\n",
                "| Component | Description |\n",
                "|-----------|-------------|\n",
                "| Data Pipeline | CIFAR-10 binary loader with normalization to [0,1] |\n",
                "| Conv2D | 6 nested loops: output channels, height, width, kernel h/w, input channels |\n",
                "| ReLU | Element-wise max(0, x) |\n",
                "| MaxPool2D | 2x2 window max with stride 2 |\n",
                "| Upsample2D | Nearest neighbor interpolation |\n",
                "| Loss | MSE between input and reconstruction |\n",
                "\n",
                "**Key Code: Conv2D Forward (src/cpu/layers/conv2d.cpp)**\n",
                "```cpp\n",
                "std::vector<float> Conv2D::forward(const std::vector<float>& input, int H, int W) {\n",
                "    m_outH = (H + 2 * m_padding - m_kernelSize) / m_stride + 1;\n",
                "    m_outW = (W + 2 * m_padding - m_kernelSize) / m_stride + 1;\n",
                "    std::vector<float> output(m_outH * m_outW * m_outChannels, 0.0f);\n",
                "    \n",
                "    for (int oc = 0; oc < m_outChannels; ++oc) {\n",
                "        for (int oh = 0; oh < m_outH; ++oh) {\n",
                "            for (int ow = 0; ow < m_outW; ++ow) {\n",
                "                float sum = m_bias[oc];\n",
                "                for (int kh = 0; kh < m_kernelSize; ++kh)\n",
                "                    for (int kw = 0; kw < m_kernelSize; ++kw)\n",
                "                        for (int ic = 0; ic < m_inChannels; ++ic) {\n",
                "                            int ih = oh * m_stride + kh - m_padding;\n",
                "                            int iw = ow * m_stride + kw - m_padding;\n",
                "                            sum += getPaddedValue(input, ih, iw, ic) * m_weights[wIdx];\n",
                "                        }\n",
                "                output[(oh * m_outW + ow) * m_outChannels + oc] = sum;\n",
                "            }\n",
                "        }\n",
                "    }\n",
                "    return output;\n",
                "}\n",
                "```\n",
                "\n",
                "**Key Takeaway:** 6 nested loops in convolution account for ~90% of compute time. This is the primary optimization target for GPU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.2: GPU Basic (Naive)\n",
                "\n",
                "**Objective:** Port CPU code to GPU with basic parallelization. Verify correctness against CPU baseline.\n",
                "\n",
                "**Parallelization Strategy:**\n",
                "\n",
                "| Layer | Thread Mapping | Grid/Block Config |\n",
                "|-------|----------------|-------------------|\n",
                "| Conv2D | 1 thread = 1 output element | grid((N*H*W*C+255)/256), block(256) |\n",
                "| ReLU | 1 thread = 1 element | Same as above |\n",
                "| MaxPool | 1 thread = 1 output pixel | grid((N*outH*outW*C+255)/256), block(256) |\n",
                "| Upsample | 1 thread = 1 output pixel | Same as above |\n",
                "\n",
                "**Key Code: Naive Conv2D Kernel (src/gpu/kernels/forward/conv2d.cu)**\n",
                "```cpp\n",
                "__global__ void conv2dForwardKernel(\n",
                "    const float* input, const float* weights, const float* bias, float* output,\n",
                "    int batch, int inH, int inW, int inC, int outH, int outW, int outC,\n",
                "    int kernelSize, int padding, int stride\n",
                ") {\n",
                "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
                "    if (idx >= batch * outH * outW * outC) return;\n",
                "    \n",
                "    // Decode NHWC index\n",
                "    int c = idx % outC;\n",
                "    int w = (idx / outC) % outW;\n",
                "    int h = (idx / (outC * outW)) % outH;\n",
                "    int n = idx / (outC * outW * outH);\n",
                "    \n",
                "    float sum = 0.0f;\n",
                "    for (int kh = 0; kh < kernelSize; kh++)\n",
                "        for (int kw = 0; kw < kernelSize; kw++)\n",
                "            for (int ic = 0; ic < inC; ic++) {\n",
                "                int in_h = h * stride + kh - padding;\n",
                "                int in_w = w * stride + kw - padding;\n",
                "                if (in_h >= 0 && in_h < inH && in_w >= 0 && in_w < inW)\n",
                "                    sum += input[...] * weights[...];\n",
                "            }\n",
                "    output[idx] = sum + bias[c];\n",
                "}\n",
                "```\n",
                "\n",
                "**Key Takeaway:** Basic parallelization achieves significant speedup but is memory-bandwidth bound due to uncoalesced global memory accesses in convolution kernel."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.3: GPU Optimized v1 (NCHW + Warp Shuffle)\n",
                "\n",
                "**Optimization Focus:** Improve memory access patterns and reduce synchronization overhead.\n",
                "\n",
                "**Optimizations Applied:**\n",
                "\n",
                "| Technique | Description | Expected Benefit |\n",
                "|-----------|-------------|------------------|\n",
                "| NCHW Layout | Change from NHWC to NCHW for better coalescing | Improved memory bandwidth |\n",
                "| 2D Grid Indexing | Map thread blocks to spatial dimensions | Better locality |\n",
                "| Warp Shuffle Reduction | Use `__shfl_down_sync()` for reductions | Avoid shared memory latency |\n",
                "\n",
                "**Key Code: NCHW Conv2D with 2D Grid**\n",
                "```cpp\n",
                "__global__ void conv2dForwardNCHW(\n",
                "    const float* __restrict__ input,\n",
                "    const float* __restrict__ weights,\n",
                "    float* __restrict__ output, ...\n",
                ") {\n",
                "    // 2D grid maps to spatial dimensions\n",
                "    int ox = blockIdx.x * blockDim.x + threadIdx.x;  // Width\n",
                "    int oy = blockIdx.y * blockDim.y + threadIdx.y;  // Height\n",
                "    int oc = blockIdx.z;                             // Output channel\n",
                "    \n",
                "    if (ox < outW && oy < outH) {\n",
                "        float sum = 0.0f;\n",
                "        #pragma unroll\n",
                "        for (int ic = 0; ic < inC; ic++)\n",
                "            for (int kh = 0; kh < 3; kh++)\n",
                "                for (int kw = 0; kw < 3; kw++)\n",
                "                    sum += input[NCHW_IDX(...)] * weights[...];\n",
                "        output[oc * outH * outW + oy * outW + ox] = sum + bias[oc];\n",
                "    }\n",
                "}\n",
                "```\n",
                "\n",
                "**Analysis:** NCHW layout ensures consecutive threads access consecutive memory addresses, maximizing memory bandwidth utilization."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.4: GPU Optimized v2 (im2col + cuBLAS GEMM)\n",
                "\n",
                "**Optimization Focus:** Transform convolution into highly-optimized matrix multiplication.\n",
                "\n",
                "**Optimizations Applied:**\n",
                "\n",
                "| Technique | Description | Expected Benefit |\n",
                "|-----------|-------------|------------------|\n",
                "| im2col Transformation | Unroll input patches into columns | Enable GEMM |\n",
                "| cuBLAS SGEMM | Use NVIDIA's optimized BLAS library | Peak hardware utilization |\n",
                "| col2im for Backward | Reverse transformation for gradients | Consistent optimization |\n",
                "\n",
                "**Key Code: im2col + GEMM Convolution**\n",
                "```cpp\n",
                "void conv2dGEMM(const float* input, const float* weights, float* output, ...) {\n",
                "    // Step 1: im2col - transform input patches to columns\n",
                "    // Input: (N, C, H, W) -> Column matrix: (C*K*K, N*outH*outW)\n",
                "    im2col_gpu(input, im2colBuffer, ...);\n",
                "    \n",
                "    // Step 2: GEMM - matrix multiplication\n",
                "    // Weights: (outC, C*K*K) x Columns: (C*K*K, N*outH*outW)\n",
                "    // = Output: (outC, N*outH*outW)\n",
                "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,\n",
                "        M, N, K,           // outC, batch*outH*outW, inC*k*k\n",
                "        &alpha, weights, M,\n",
                "        im2colBuffer, K,\n",
                "        &beta, output, M);\n",
                "}\n",
                "```\n",
                "\n",
                "**Analysis:** cuBLAS SGEMM achieves near-peak GPU performance through optimized memory access patterns, register blocking, and tensor core utilization (on supported hardware)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 3: Benchmarking"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run benchmark: Compare CPU vs all GPU versions\n",
                "# epochs=3, samples=100 for quick comparison\n",
                "!scripts/benchmark.sh --epochs 3 --samples 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU-only benchmark with more samples\n",
                "!scripts/benchmark.sh --epochs 3 --samples 1000 --gpu-only"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Performance Summary\n",
                "\n",
                "**Benchmark Results (Tesla T4 GPU):**\n",
                "\n",
                "| Phase | Time/Epoch | Speedup vs CPU | Key Technique |\n",
                "|-------|------------|----------------|---------------|\n",
                "| CPU Baseline | 169.18 sec* | 1.0x | Sequential |\n",
                "| GPU Naive | 500.57 sec | 169x | Basic Parallelization |\n",
                "| GPU Opt v1 | 247.15 sec | 342x | NCHW + 2D Grid + Warp Shuffle |\n",
                "| GPU Opt v2 | 50.52 sec | 1690x | im2col + cuBLAS GEMM |\n",
                "\n",
                "***Notes:***\n",
                "- *CPU baseline measured on 100 samples only. Estimated full training: ~23.5 hours/epoch.*\n",
                "- *GPU values: average per epoch from 50,000 samples, 3 epochs.*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize benchmark results\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "results_file = '/content/AutoEncoder-CUDA/results/benchmark.csv'\n",
                "\n",
                "if os.path.exists(results_file):\n",
                "    df = pd.read_csv(results_file)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    # Time comparison (log scale)\n",
                "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12'][:len(df)]\n",
                "    bars = axes[0].bar(df['Version'], df['Time_ms'], color=colors)\n",
                "    axes[0].set_ylabel('Time (ms)')\n",
                "    axes[0].set_title('Training Time Comparison')\n",
                "    axes[0].set_yscale('log')\n",
                "    for bar, t in zip(bars, df['Time_ms']):\n",
                "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{t}ms', \n",
                "                     ha='center', va='bottom', fontsize=9)\n",
                "    \n",
                "    # Speedup chart\n",
                "    if 'CPU' in df['Version'].values:\n",
                "        cpu_time = df[df['Version'] == 'CPU']['Time_ms'].values[0]\n",
                "    else:\n",
                "        cpu_time = df['Time_ms'].max()  # Use slowest as baseline\n",
                "    speedups = [cpu_time / t for t in df['Time_ms']]\n",
                "    axes[1].bar(df['Version'], speedups, color=colors)\n",
                "    axes[1].set_ylabel('Speedup')\n",
                "    axes[1].set_title('GPU Speedup vs Baseline')\n",
                "    axes[1].axhline(y=20, color='red', linestyle='--', alpha=0.7, label='Target (20x)')\n",
                "    axes[1].legend()\n",
                "    for i, s in enumerate(speedups):\n",
                "        axes[1].text(i, s + 2, f'{s:.1f}x', ha='center', fontsize=9)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print('No benchmark results found. Run benchmark cell above first.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 4: SVM Classification\n",
                "\n",
                "**Pipeline:**\n",
                "1. Extract 8,192-dim features from trained encoder\n",
                "2. Train RBF-SVM classifier using ThunderSVM (GPU-accelerated)\n",
                "3. Evaluate on CIFAR-10 test set\n",
                "\n",
                "**Note:** SVM training requires ~17GB RAM. Use Google Colab Pro/Pro+ with High RAM mode."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option A: Evaluate with Pre-trained Weights (Recommended)\n",
                "\n",
                "Download pre-trained encoder and SVM weights from Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download pre-trained weights\n",
                "!./scripts/download_weights.sh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate with downloaded weights\n",
                "!./run.sh evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option B: Full Pipeline (Train from Scratch)\n",
                "\n",
                "Train autoencoder → Train SVM → Evaluate (~25 minutes total on T4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline: uncomment to run\n",
                "# !./run.sh pipeline --epochs 20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option C: Train Components Separately"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train autoencoder only (quick test)\n",
                "# !./run.sh train-autoencoder --epochs 5 --samples 1000\n",
                "\n",
                "# Train autoencoder (full - ~20 minutes)\n",
                "# !./run.sh train-autoencoder --epochs 20"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train SVM using default encoder weights\n",
                "# !./run.sh train-svm\n",
                "\n",
                "# Or with custom encoder weights:\n",
                "# !./run.sh train-svm --encoder-weights ./checkpoints/encoder_custom.weights"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.1 Classification Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix visualization\n",
                "confusion_csv = '/content/AutoEncoder-CUDA/results/confusion_matrix.csv'\n",
                "\n",
                "if os.path.exists(confusion_csv):\n",
                "    import seaborn as sns\n",
                "    cm_df = pd.read_csv(confusion_csv, index_col=0)\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', \n",
                "                xticklabels=class_names, yticklabels=class_names)\n",
                "    plt.title('Confusion Matrix')\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('True')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Per-class accuracy\n",
                "    cm = cm_df.values\n",
                "    per_class = np.diag(cm) / cm.sum(axis=1) * 100\n",
                "    overall = np.trace(cm) / cm.sum() * 100\n",
                "    \n",
                "    print(f\"\\nOverall Accuracy: {overall:.2f}%\")\n",
                "    print(f\"\\nPer-class Accuracy:\")\n",
                "    for i, name in enumerate(class_names):\n",
                "        print(f\"  {name:<12}: {per_class[i]:.1f}%\")\n",
                "else:\n",
                "    print(\"Confusion matrix not available. Run evaluation first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 5: Lessons Learned\n",
                "\n",
                "## 5.1 Technical Insights\n",
                "\n",
                "**CUDA Programming:**\n",
                "- Thread coalescing is critical: NCHW layout ensures consecutive threads access consecutive addresses\n",
                "- im2col + GEMM transforms convolution into highly-optimized matrix multiplication\n",
                "- cuBLAS achieves near-peak performance through optimized register blocking\n",
                "- Warp shuffle operations (`__shfl_down_sync()`) avoid shared memory latency for reductions\n",
                "\n",
                "**Deep Learning:**\n",
                "- He initialization (std = sqrt(2/fan_in)) prevents gradient explosion in ReLU networks\n",
                "- Gradient clipping (max_norm=1.0) stabilizes training for deep networks\n",
                "- Autoencoder features capture visual patterns but have limited discriminative power vs supervised learning\n",
                "\n",
                "**Performance Optimization:**\n",
                "- Naive GPU is memory-bandwidth bound, not compute-bound\n",
                "- GEMM-based convolution provides the largest speedup by leveraging vendor-optimized libraries\n",
                "- Profile-guided optimization is essential; assumptions about bottlenecks are often wrong\n",
                "\n",
                "## 5.2 Challenges and Solutions\n",
                "\n",
                "| Challenge | Problem | Solution |\n",
                "|-----------|---------|----------|\n",
                "| Gradient Explosion | Training loss became NaN | He initialization + gradient clipping |\n",
                "| Memory Bandwidth | Naive kernel ~10% peak FLOPS | im2col + cuBLAS GEMM |\n",
                "| SVM RAM Usage | ThunderSVM OOM on 60K samples | High RAM mode (17GB peak) |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 6: Conclusion\n",
                "\n",
                "## 6.1 Summary\n",
                "\n",
                "| Metric | Target | Achieved | Status |\n",
                "|--------|--------|----------|--------|\n",
                "| Training time | < 10 min | ~51s/epoch (v2) | ✅ Exceeded |\n",
                "| GPU speedup | > 20x | ~1690x (v2 vs CPU) | ✅ Exceeded |\n",
                "| Test accuracy | 60-65% | 60.08% | ✅ Met |\n",
                "| Feature extraction | < 20s | ~15s (60K images) | ✅ Met |\n",
                "\n",
                "## 6.2 Key Achievements\n",
                "\n",
                "| Achievement | Value |\n",
                "|-------------|-------|\n",
                "| Maximum speedup achieved | 1690x (GPU-v2 vs CPU) |\n",
                "| Best-performing optimization | im2col + cuBLAS GEMM |\n",
                "| Classification accuracy | 60.08% on CIFAR-10 test set |\n",
                "| Technical skills mastered | CUDA kernel optimization, cuBLAS, memory hierarchy |\n",
                "\n",
                "## 6.3 Accomplishments\n",
                "\n",
                "| Component | Status |\n",
                "|-----------|--------|\n",
                "| CIFAR-10 Data Loader | ✅ Complete |\n",
                "| CPU Autoencoder Baseline | ✅ Complete |\n",
                "| GPU Naive Implementation | ✅ Complete |\n",
                "| GPU Opt v1 (NCHW + Warp Shuffle) | ✅ Complete |\n",
                "| GPU Opt v2 (im2col + cuBLAS) | ✅ Complete |\n",
                "| SVM Integration (ThunderSVM) | ✅ Complete |\n",
                "\n",
                "## 6.4 Limitations\n",
                "\n",
                "- 60% accuracy is significantly lower than supervised CNN (~96%)\n",
                "- SVM requires high RAM (~17GB) due to ThunderSVM implementation\n",
                "- No multi-GPU support implemented\n",
                "- Fixed batch size (not dynamically tuned per GPU memory)\n",
                "\n",
                "## 6.5 Future Work\n",
                "\n",
                "**Performance Improvements:**\n",
                "- Winograd convolution for 3x3 kernels (reduces multiplications)\n",
                "- Multi-stream training to overlap H2D transfer with computation\n",
                "- FP16 mixed precision training for 2x memory bandwidth\n",
                "\n",
                "**Accuracy Improvements:**\n",
                "- Variational Autoencoder (VAE) for better latent space structure\n",
                "- Supervised fine-tuning after unsupervised pre-training\n",
                "- Alternative classifiers (Random Forest, Neural Network head)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Appendix A: Project Structure\n",
                "\n",
                "```text\n",
                "AutoEncoder-CUDA/\n",
                "├───checkpoints/          # Saved model weights\n",
                "│   ├── encoder.weights   # Pre-trained encoder\n",
                "│   └── svm.bin           # Pre-trained SVM model\n",
                "├───data/                 # CIFAR-10 binary files\n",
                "├───docs/                 # Documentation\n",
                "├───external/             # Third-party libraries (ThunderSVM)\n",
                "├───notebooks/            # Jupyter notebooks\n",
                "├───scripts/              # Utility scripts\n",
                "│   ├── benchmark.sh      # Performance benchmarking\n",
                "│   ├── download_cifar10.sh\n",
                "│   └── download_weights.sh\n",
                "└───src/                  # Source code\n",
                "    ├───cpu/              # CPU baseline\n",
                "    └───gpu/              # CUDA implementation\n",
                "        ├───kernels/      # CUDA kernels\n",
                "        │   ├───forward/  # Forward pass\n",
                "        │   ├───backward/ # Backpropagation\n",
                "        │   └───gemm/     # im2col + GEMM\n",
                "        └───svm/          # SVM wrapper\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Appendix B: Usage Reference\n",
                "\n",
                "```bash\n",
                "# Commands\n",
                "./run.sh train-autoencoder   # Train autoencoder only\n",
                "./run.sh train-svm           # Train SVM with existing encoder\n",
                "./run.sh evaluate            # Evaluate with pre-trained weights\n",
                "./run.sh pipeline            # Full: train -> SVM -> evaluate\n",
                "\n",
                "# Options\n",
                "--device cpu|gpu             # Device (default: gpu)\n",
                "--version naive|v1|v2        # GPU version (default: v2)\n",
                "--epochs N                   # Training epochs (default: 20)\n",
                "--samples N                  # Limit samples, 0=all\n",
                "--encoder-weights PATH       # Input encoder weights\n",
                "--svm-model PATH             # Input SVM model\n",
                "\n",
                "# Examples\n",
                "./run.sh train-autoencoder --epochs 5 --samples 1000   # Quick test\n",
                "./run.sh train-autoencoder --version v1 --epochs 20    # Use v1 optimizer\n",
                "./run.sh evaluate --encoder-weights ./checkpoints/custom.weights\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "**End of Report**"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}