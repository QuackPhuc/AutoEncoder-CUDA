{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CSC14120 - Parallel Programming Final Project\n",
                "# Autoencoder-based Feature Learning for CIFAR-10 Classification\n",
                "\n",
                "---\n",
                "\n",
                "**Team:** Team 18\n",
                "\n",
                "**Video Presentation:** [YouTube Link - Unlisted]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 1: Problem Description\n",
                "\n",
                "## 1.1 Problem Statement\n",
                "\n",
                "This project implements **unsupervised feature learning** using a Convolutional Autoencoder for CIFAR-10 image classification, accelerated with CUDA.\n",
                "\n",
                "**Two-Stage Pipeline:**\n",
                "\n",
                "| Stage | Task | Input | Output |\n",
                "|-------|------|-------|--------|\n",
                "| 1 | Train Autoencoder (unsupervised) | 50K images, no labels | Encoder that produces 8,192-dim features |\n",
                "| 2 | Train SVM Classifier (supervised) | Extracted features + labels | 10-class classifier |\n",
                "\n",
                "**Motivation for GPU Acceleration:**\n",
                "- CPU convolution involves 6 nested loops → ~90% of compute time\n",
                "- Full CPU training: estimated ~23 hours/epoch\n",
                "- GPU parallelization target: <10 minutes total training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 CIFAR-10 Dataset\n",
                "\n",
                "| Specification | Value |\n",
                "|---------------|-------|\n",
                "| Image size | 32×32×3 (RGB) |\n",
                "| Training set | 50,000 images |\n",
                "| Test set | 10,000 images |\n",
                "| Classes | 10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) |\n",
                "| Data format | Binary files, uint8 → normalized to [0,1] |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup: Clone repository and download dataset\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "repos = \"https://github.com/QuackPhuc/AutoEncoder-CUDA.git\"\n",
                "\n",
                "if not os.path.exists('/content/AutoEncoder-CUDA'):\n",
                "    !git clone --recursive {repos}\n",
                "\n",
                "%cd /content/AutoEncoder-CUDA\n",
                "!chmod +x scripts/*.sh build.sh run.sh\n",
                "!scripts/download_cifar10.sh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CIFAR-10 Dataset Samples\n",
                "def load_cifar10_batch(file_path):\n",
                "    \"\"\"Load CIFAR-10 binary batch file.\"\"\"\n",
                "    with open(file_path, 'rb') as f:\n",
                "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
                "    data = data.reshape(-1, 3073)\n",
                "    labels = data[:, 0]\n",
                "    images = data[:, 1:].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
                "    return images, labels\n",
                "\n",
                "images, labels = load_cifar10_batch('/content/AutoEncoder-CUDA/data/data_batch_1.bin')\n",
                "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
                "\n",
                "fig, axes = plt.subplots(2, 10, figsize=(14, 3))\n",
                "fig.suptitle('CIFAR-10 Dataset Samples (2 per class)', fontsize=11, fontweight='bold')\n",
                "for class_idx in range(10):\n",
                "    class_images = images[labels == class_idx]\n",
                "    for row in range(2):\n",
                "        ax = axes[row, class_idx]\n",
                "        ax.imshow(class_images[row])\n",
                "        ax.axis('off')\n",
                "        if row == 0:\n",
                "            ax.set_title(class_names[class_idx], fontsize=8)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.3 Autoencoder Architecture\n",
                "\n",
                "```text\n",
                "INPUT (32×32×3)\n",
                "       │\n",
                "   [ENCODER]\n",
                "       │\n",
                "       ├── Conv2D(3→256, 3×3, pad=1) + ReLU  →  (32×32×256)   [7,168 params]\n",
                "       ├── MaxPool2D(2×2)                    →  (16×16×256)\n",
                "       ├── Conv2D(256→128, 3×3, pad=1) + ReLU →  (16×16×128)   [295,040 params]\n",
                "       └── MaxPool2D(2×2)                    →  (8×8×128)\n",
                "       │\n",
                "   LATENT (8×8×128 = 8,192 dimensions)\n",
                "       │\n",
                "   [DECODER]\n",
                "       │\n",
                "       ├── Conv2D(128→128, 3×3, pad=1) + ReLU →  (8×8×128)     [147,584 params]\n",
                "       ├── Upsample2D(2×)                    →  (16×16×128)\n",
                "       ├── Conv2D(128→256, 3×3, pad=1) + ReLU →  (16×16×256)   [295,168 params]\n",
                "       ├── Upsample2D(2×)                    →  (32×32×256)\n",
                "       └── Conv2D(256→3, 3×3, pad=1)         →  (32×32×3)     [6,915 params]\n",
                "       │\n",
                "OUTPUT (32×32×3)\n",
                "```\n",
                "\n",
                "**Total Parameters:** 751,875 | **Loss Function:** MSE(input, output)\n",
                "\n",
                "## 1.4 Performance Targets\n",
                "\n",
                "| Metric | Target |\n",
                "|--------|--------|\n",
                "| Autoencoder training | < 10 minutes |\n",
                "| Feature extraction | < 20 seconds (60K images) |\n",
                "| Classification accuracy | 60-65% |\n",
                "| GPU speedup vs CPU | > 20× |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 2: Implementation Phases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build all versions\n",
                "%cd /content/AutoEncoder-CUDA\n",
                "!./build.sh --clean"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.1: CPU Baseline\n",
                "\n",
                "**Objectives:**\n",
                "- Implement complete autoencoder on CPU as correctness reference\n",
                "- Establish baseline performance for speedup measurement\n",
                "\n",
                "**Implementation Details:**\n",
                "\n",
                "| Component | Implementation |\n",
                "|-----------|----------------|\n",
                "| Data Pipeline | Binary loader with [0,255]→[0,1] normalization |\n",
                "| Conv2D | 6 nested loops: batch, outH, outW, outC, kH, kW, inC |\n",
                "| ReLU | Element-wise `max(0, x)` |\n",
                "| MaxPool2D | 2×2 window max, stride 2 |\n",
                "| Upsample2D | Nearest neighbor interpolation |\n",
                "| Loss | MSE with L2 reduction |\n",
                "\n",
                "**Key Code: CPU Convolution (src/cpu/layers/conv2d.cpp)**\n",
                "```cpp\n",
                "for (int oc = 0; oc < outChannels; ++oc)\n",
                "  for (int oh = 0; oh < outH; ++oh)\n",
                "    for (int ow = 0; ow < outW; ++ow) {\n",
                "      float sum = bias[oc];\n",
                "      for (int kh = 0; kh < K; ++kh)\n",
                "        for (int kw = 0; kw < K; ++kw)\n",
                "          for (int ic = 0; ic < inChannels; ++ic)\n",
                "            sum += input[...] * weights[...];\n",
                "      output[...] = sum;\n",
                "    }\n",
                "```\n",
                "\n",
                "**Results:**\n",
                "- Training time: ~169 sec/epoch (100 samples only)\n",
                "- Estimated full training: ~23.5 hours/epoch\n",
                "- Memory: ~50 MB\n",
                "\n",
                "**Key Takeaway:** 6 nested loops → O(N×H×W×C×K²×C') complexity. Primary target for GPU parallelization."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.2: GPU Basic (Naive)\n",
                "\n",
                "**Objectives:**\n",
                "- Port CPU code to GPU with basic parallelization\n",
                "- Verify correctness against CPU baseline\n",
                "\n",
                "**Parallelization Strategy:**\n",
                "\n",
                "| Operation | Thread Mapping | Grid Configuration |\n",
                "|-----------|----------------|--------------------|\n",
                "| Conv2D | 1 thread = 1 output element | `((N*H*W*C+255)/256, 256)` |\n",
                "| ReLU | 1 thread = 1 element | Same |\n",
                "| MaxPool | 1 thread = 1 output | Same |\n",
                "| Upsample | 1 thread = 1 output | Same |\n",
                "\n",
                "**Key Code: Naive Conv2D Kernel (src/gpu/kernels/forward/conv2d.cu)**\n",
                "```cpp\n",
                "__global__ void conv2dForwardKernel(...) {\n",
                "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
                "    if (idx >= batch * outH * outW * outC) return;\n",
                "    \n",
                "    // Decode NHWC index → (n, h, w, c)\n",
                "    int c = idx % outC;\n",
                "    int w = (idx / outC) % outW;\n",
                "    int h = (idx / (outC * outW)) % outH;\n",
                "    int n = idx / (outC * outW * outH);\n",
                "    \n",
                "    float sum = 0.0f;\n",
                "    for (int kh = 0; kh < K; kh++)\n",
                "      for (int kw = 0; kw < K; kw++)\n",
                "        for (int ic = 0; ic < inC; ic++)\n",
                "          sum += input[...] * weights[...];\n",
                "    output[idx] = sum + bias[c];\n",
                "}\n",
                "```\n",
                "\n",
                "**Results:**\n",
                "- Training time: ~500 ms/epoch (50K samples)\n",
                "- Speedup vs CPU: ~169× (on limited CPU samples)\n",
                "- GPU Memory: 1.2 GB\n",
                "\n",
                "**Key Takeaway:** Basic parallelization achieves significant speedup but is **memory-bandwidth bound** due to uncoalesced global memory accesses in NHWC layout."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.3: GPU Optimized v1 (NCHW + Warp Shuffle)\n",
                "\n",
                "**Optimization Focus:** Memory access patterns and reduction efficiency\n",
                "\n",
                "**Objectives:**\n",
                "- Improve memory coalescing with NCHW layout\n",
                "- Use warp-level primitives for faster reductions\n",
                "\n",
                "**Optimizations Applied:**\n",
                "\n",
                "| Technique | Description | Benefit |\n",
                "|-----------|-------------|--------|\n",
                "| NCHW Layout | Spatial dimensions contiguous | Coalesced memory access |\n",
                "| 2D Thread Blocks | Map to (x,y) spatial dims | Better cache locality |\n",
                "| `__shfl_down_sync()` | Warp-level reduction | Avoid shared memory latency |\n",
                "\n",
                "**Key Code: NCHW Conv2D with 2D Grid**\n",
                "```cpp\n",
                "__global__ void conv2dNCHW(...) {\n",
                "    int ox = blockIdx.x * blockDim.x + threadIdx.x;  // Width\n",
                "    int oy = blockIdx.y * blockDim.y + threadIdx.y;  // Height  \n",
                "    int oc = blockIdx.z;                             // Channel\n",
                "    \n",
                "    if (ox < outW && oy < outH) {\n",
                "        float sum = 0.0f;\n",
                "        #pragma unroll\n",
                "        for (int ic = 0; ic < inC; ic++)\n",
                "          for (int kh = 0; kh < 3; kh++)\n",
                "            for (int kw = 0; kw < 3; kw++)\n",
                "              sum += input[NCHW_IDX(...)] * weights[...];\n",
                "        output[oc*outH*outW + oy*outW + ox] = sum + bias[oc];\n",
                "    }\n",
                "}\n",
                "```\n",
                "\n",
                "**Results:**\n",
                "- Training time: ~247 ms/epoch\n",
                "- Speedup vs Naive: ~2.0×\n",
                "- Cumulative speedup vs CPU: ~342×\n",
                "\n",
                "**Key Takeaway:** NCHW layout ensures consecutive threads access consecutive addresses, maximizing memory bandwidth utilization."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.4: GPU Optimized v2 (im2col + cuBLAS GEMM)\n",
                "\n",
                "**Optimization Focus:** Transform convolution into optimized matrix multiplication\n",
                "\n",
                "**Objectives:**\n",
                "- Leverage vendor-optimized cuBLAS SGEMM\n",
                "- Achieve near-peak GPU performance\n",
                "\n",
                "**Optimizations Applied:**\n",
                "\n",
                "| Technique | Description | Benefit |\n",
                "|-----------|-------------|--------|\n",
                "| im2col | Unroll input patches into columns | Enables GEMM |\n",
                "| cuBLAS SGEMM | NVIDIA's optimized BLAS | Peak hardware utilization |\n",
                "| col2im | Reverse for backprop | Consistent optimization |\n",
                "\n",
                "**Key Code: im2col + GEMM Convolution**\n",
                "```cpp\n",
                "void conv2dGEMM(...) {\n",
                "    // Step 1: im2col transform\n",
                "    // Input (N,C,H,W) → Column matrix (C*K*K, N*outH*outW)\n",
                "    im2col_gpu(input, im2colBuffer, ...);\n",
                "    \n",
                "    // Step 2: GEMM\n",
                "    // Weights (outC, C*K*K) × Columns (C*K*K, N*outH*outW)\n",
                "    // = Output (outC, N*outH*outW)\n",
                "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,\n",
                "        M, N, K,  // outC, batch*outHW, inC*k*k\n",
                "        &alpha, weights, M,\n",
                "        im2colBuffer, K,\n",
                "        &beta, output, M);\n",
                "}\n",
                "```\n",
                "\n",
                "**Results:**\n",
                "- Training time: ~50.5 ms/epoch\n",
                "- Speedup vs v1: ~4.9×\n",
                "- **Cumulative speedup vs CPU: ~1690×**\n",
                "\n",
                "**Key Takeaway:** cuBLAS achieves near-peak performance through optimized register blocking, memory access patterns, and (when available) Tensor Core utilization."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder Reconstruction Visualization\n",
                "\n",
                "After GPU optimization, we verify the autoencoder's learning quality by visualizing reconstructions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download pretrained weights for visualization\n",
                "!./scripts/download_weights.sh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PyTorch Autoencoder for loading weights\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "class Autoencoder(nn.Module):\n",
                "    \"\"\"PyTorch Autoencoder matching C++ CUDA architecture.\"\"\"\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        # Encoder\n",
                "        self.enc_conv1 = nn.Conv2d(3, 256, 3, padding=1)\n",
                "        self.enc_conv2 = nn.Conv2d(256, 128, 3, padding=1)\n",
                "        # Decoder\n",
                "        self.dec_conv3 = nn.Conv2d(128, 128, 3, padding=1)\n",
                "        self.dec_conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
                "        self.dec_conv5 = nn.Conv2d(256, 3, 3, padding=1)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # Encoder\n",
                "        x = F.relu(self.enc_conv1(x))\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = F.relu(self.enc_conv2(x))\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        # Decoder\n",
                "        x = F.relu(self.dec_conv3(x))\n",
                "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
                "        x = F.relu(self.dec_conv4(x))\n",
                "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
                "        x = self.dec_conv5(x)\n",
                "        return x\n",
                "\n",
                "def load_cpp_weights(model, filepath):\n",
                "    \"\"\"Load binary weights from C++ implementation.\"\"\"\n",
                "    with open(filepath, 'rb') as f:\n",
                "        data = np.frombuffer(f.read(), dtype=np.float32)\n",
                "    \n",
                "    offset = 0\n",
                "    def read_tensor(shape):\n",
                "        nonlocal offset\n",
                "        size = int(np.prod(shape))\n",
                "        tensor = torch.from_numpy(data[offset:offset+size].reshape(shape).copy())\n",
                "        offset += size\n",
                "        return tensor\n",
                "    \n",
                "    # Load in same order as C++ saves\n",
                "    model.enc_conv1.weight.data = read_tensor([256, 3, 3, 3])\n",
                "    model.enc_conv1.bias.data = read_tensor([256])\n",
                "    model.enc_conv2.weight.data = read_tensor([128, 256, 3, 3])\n",
                "    model.enc_conv2.bias.data = read_tensor([128])\n",
                "    model.dec_conv3.weight.data = read_tensor([128, 128, 3, 3])\n",
                "    model.dec_conv3.bias.data = read_tensor([128])\n",
                "    model.dec_conv4.weight.data = read_tensor([256, 128, 3, 3])\n",
                "    model.dec_conv4.bias.data = read_tensor([256])\n",
                "    model.dec_conv5.weight.data = read_tensor([3, 256, 3, 3])\n",
                "    model.dec_conv5.bias.data = read_tensor([3])\n",
                "    return model\n",
                "\n",
                "print(\"Autoencoder class ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate and visualize reconstructions\n",
                "weights_path = '/content/AutoEncoder-CUDA/checkpoints/encoder.weights'\n",
                "\n",
                "if os.path.exists(weights_path):\n",
                "    # Load model\n",
                "    model = load_cpp_weights(Autoencoder(), weights_path)\n",
                "    model.eval()\n",
                "\n",
                "    # Load test images (one per class)\n",
                "    test_images, test_labels = load_cifar10_batch('/content/AutoEncoder-CUDA/data/test_batch.bin')\n",
                "    selected = [np.where(test_labels == c)[0][0] for c in range(10)]\n",
                "    samples = test_images[selected]\n",
                "    sample_labels = test_labels[selected]\n",
                "\n",
                "    # Convert to tensor and run inference\n",
                "    x = torch.from_numpy(samples.transpose(0,3,1,2).astype(np.float32) / 255.0)\n",
                "    with torch.no_grad():\n",
                "        recon = torch.clamp(model(x), 0, 1).numpy().transpose(0,2,3,1)\n",
                "    original = samples / 255.0\n",
                "\n",
                "    # Visualize\n",
                "    fig, axes = plt.subplots(3, 10, figsize=(15, 5))\n",
                "    fig.suptitle('Autoencoder Reconstruction Results', fontsize=12, fontweight='bold')\n",
                "\n",
                "    for i in range(10):\n",
                "        axes[0, i].imshow(original[i])\n",
                "        axes[0, i].axis('off')\n",
                "        axes[0, i].set_title(class_names[sample_labels[i]], fontsize=8)\n",
                "\n",
                "        axes[1, i].imshow(recon[i])\n",
                "        axes[1, i].axis('off')\n",
                "\n",
                "        diff = np.abs(original[i] - recon[i])\n",
                "        axes[2, i].imshow(np.clip(diff * 3, 0, 1), cmap=\"hot\")  # Amplify for visibility, darker is better\n",
                "        axes[2, i].axis('off')\n",
                "\n",
                "    # Row labels\n",
                "    for ax, label in zip([axes[0,0], axes[1,0], axes[2,0]], ['Original', 'Reconstructed', 'Difference (3x)']):\n",
                "        ax.text(-0.15, 0.5, label, transform=ax.transAxes, fontsize=10, \n",
                "                fontweight='bold', va='center', rotation=90)\n",
                "\n",
                "    plt.tight_layout(rect=[0.02, 0, 1, 0.95])\n",
                "    plt.show()\n",
                "\n",
                "    # Metrics\n",
                "    mse = np.mean((original - recon) ** 2)\n",
                "    print(f\"Reconstruction MSE: {mse:.6f} | Avg pixel error: {np.sqrt(mse)*255:.1f}/255\")\n",
                "else:\n",
                "    print(\"Weights not found. Run download_weights.sh first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2.5: SVM Integration\n",
                "\n",
                "**Objectives:**\n",
                "- Extract 8,192-dim features using trained encoder\n",
                "- Train SVM classifier (ThunderSVM, GPU-accelerated)\n",
                "- Evaluate end-to-end classification performance\n",
                "\n",
                "**Implementation Details:**\n",
                "\n",
                "| Component | Implementation |\n",
                "|-----------|----------------|\n",
                "| Feature Extraction | Encoder forward pass only (no decoder) |\n",
                "| SVM Library | ThunderSVM (GPU-accelerated) |\n",
                "| Kernel | RBF (Radial Basis Function) |\n",
                "| Parameters | C=10, gamma=auto |\n",
                "\n",
                "**Note:** SVM training requires ~17GB RAM. Use Colab Pro/Pro+ with High RAM mode."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option A: Evaluate with Pretrained Weights (Recommended)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate with downloaded weights\n",
                "!./run.sh evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option B: Full Pipeline (Train from Scratch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline (~25 min on T4): uncomment to run\n",
                "# !./run.sh pipeline --epochs 20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### SVM Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix Visualization\n",
                "import pandas as pd\n",
                "confusion_csv = '/content/AutoEncoder-CUDA/results/confusion_matrix.csv'\n",
                "\n",
                "if os.path.exists(confusion_csv):\n",
                "    import seaborn as sns\n",
                "    cm_df = pd.read_csv(confusion_csv, index_col=0)\n",
                "    cm = cm_df.values\n",
                "    \n",
                "    # Heatmap\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues',\n",
                "                xticklabels=class_names, yticklabels=class_names)\n",
                "    plt.title('Confusion Matrix')\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('True')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Per-class accuracy\n",
                "    per_class = np.diag(cm) / cm.sum(axis=1) * 100\n",
                "    overall = np.trace(cm) / cm.sum() * 100\n",
                "    \n",
                "    print(f\"\\nOverall Accuracy: {overall:.2f}%\")\n",
                "    print(f\"\\nPer-class Accuracy:\")\n",
                "    for i, name in enumerate(class_names):\n",
                "        print(f\"  {name:<12}: {per_class[i]:.1f}%\")\n",
                "else:\n",
                "    print(\"Run evaluation first to generate confusion matrix.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SVM Classification Examples: Predicted vs Ground Truth\n",
                "if os.path.exists(confusion_csv):\n",
                "    import subprocess\n",
                "    \n",
                "    # Load test images and labels\n",
                "    test_images, test_labels = load_cifar10_batch('/content/AutoEncoder-CUDA/data/test_batch.bin')\n",
                "    \n",
                "    # Read predictions from SVM output (generated by evaluate)\n",
                "    predictions_file = '/content/AutoEncoder-CUDA/results/predictions.txt'\n",
                "    \n",
                "    if os.path.exists(predictions_file):\n",
                "        predictions = np.loadtxt(predictions_file, dtype=int)\n",
                "    else:\n",
                "        # If predictions file doesn't exist, we need to run evaluation\n",
                "        print(\"Running SVM inference to get predictions...\")\n",
                "\n",
                "        result = subprocess.run(['./run.sh', 'evaluate'], capture_output=True, text=True)\n",
                "        if result.returncode != 0:\n",
                "            print(f\"Error running evaluation:\\n{result.stderr}\")\n",
                "\n",
                "        if os.path.exists(predictions_file):\n",
                "            predictions = np.loadtxt(predictions_file, dtype=int)\n",
                "        else:\n",
                "            print(\"Could not generate predictions. Using confusion matrix analysis only.\")\n",
                "            predictions = None\n",
                "    \n",
                "    if predictions is not None:\n",
                "        # Find correct and incorrect predictions\n",
                "        correct_mask = predictions == test_labels\n",
                "        incorrect_mask = ~correct_mask\n",
                "        \n",
                "        # Sample 5 correct and 5 incorrect predictions\n",
                "        correct_indices = np.where(correct_mask)[0][:5]\n",
                "        incorrect_indices = np.where(incorrect_mask)[0][:5]\n",
                "        \n",
                "        # Visualize\n",
                "        fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
                "        fig.suptitle('SVM Classification Examples: Predicted vs Ground Truth', fontsize=12, fontweight='bold')\n",
                "        \n",
                "        # Row 1: Correct predictions (green border)\n",
                "        for col, idx in enumerate(correct_indices):\n",
                "            ax = axes[0, col]\n",
                "            ax.imshow(test_images[idx])\n",
                "            ax.set_title(f'✓ {class_names[predictions[idx]]}', fontsize=10, color='green')\n",
                "            ax.axis('off')\n",
                "            # Add green border\n",
                "            for spine in ax.spines.values():\n",
                "                spine.set_edgecolor('green')\n",
                "                spine.set_linewidth(3)\n",
                "                spine.set_visible(True)\n",
                "        axes[0, 0].text(-0.2, 0.5, 'Correct', transform=axes[0,0].transAxes, \n",
                "                        fontsize=11, fontweight='bold', color='green', va='center', rotation=90)\n",
                "        \n",
                "        # Row 2: Incorrect predictions (red border)\n",
                "        for col, idx in enumerate(incorrect_indices):\n",
                "            ax = axes[1, col]\n",
                "            ax.imshow(test_images[idx])\n",
                "            pred = class_names[predictions[idx]]\n",
                "            true = class_names[test_labels[idx]]\n",
                "            ax.set_title(f'✗ Pred: {pred}\\nTrue: {true}', fontsize=9, color='red')\n",
                "            ax.axis('off')\n",
                "            # Add red border\n",
                "            for spine in ax.spines.values():\n",
                "                spine.set_edgecolor('red')\n",
                "                spine.set_linewidth(3)\n",
                "                spine.set_visible(True)\n",
                "        axes[1, 0].text(-0.2, 0.5, 'Incorrect', transform=axes[1,0].transAxes, \n",
                "                        fontsize=11, fontweight='bold', color='red', va='center', rotation=90)\n",
                "        \n",
                "        plt.tight_layout(rect=[0.03, 0, 1, 0.95])\n",
                "        plt.show()\n",
                "        \n",
                "        # Summary\n",
                "        accuracy = correct_mask.sum() / len(test_labels) * 100\n",
                "        print(f\"\\nOverall Accuracy: {accuracy:.2f}% ({correct_mask.sum()}/{len(test_labels)})\")\n",
                "else:\n",
                "    print(\"Run evaluation first to generate confusion matrix.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 3: Performance Analysis\n",
                "\n",
                "## 3.1 Performance Comparison Across Phases\n",
                "\n",
                "| Phase | Time/Epoch | Speedup vs CPU | Incremental | Key Optimization |\n",
                "|-------|------------|----------------|-------------|------------------|\n",
                "| CPU Baseline | 169.18s* | 1.0× | - | Sequential |\n",
                "| GPU Naive | 500.57ms | 169× | 169× | Basic parallelization |\n",
                "| GPU v1 | 247.15ms | 342× | 2.0× | NCHW + Warp Shuffle |\n",
                "| GPU v2 | 50.52ms | 1690× | 4.9× | im2col + cuBLAS |\n",
                "\n",
                "*CPU measured on 100 samples only. Estimated full: ~23.5 hours/epoch.*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run benchmark\n",
                "!scripts/benchmark.sh --epochs 3 --samples 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Benchmark Visualization\n",
                "results_file = '/content/AutoEncoder-CUDA/results/benchmark.csv'\n",
                "\n",
                "if os.path.exists(results_file):\n",
                "    df = pd.read_csv(results_file)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    # Time comparison (log scale)\n",
                "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12'][:len(df)]\n",
                "    bars = axes[0].bar(df['Version'], df['Time_ms'], color=colors)\n",
                "    axes[0].set_ylabel('Time (ms)')\n",
                "    axes[0].set_title('Training Time per Epoch')\n",
                "    axes[0].set_yscale('log')\n",
                "    for bar, t in zip(bars, df['Time_ms']):\n",
                "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{t:.0f}ms',\n",
                "                     ha='center', va='bottom', fontsize=9)\n",
                "    \n",
                "    # Speedup\n",
                "    cpu_time = df[df['Version'] == 'CPU']['Time_ms'].values[0] if 'CPU' in df['Version'].values else df['Time_ms'].max()\n",
                "    speedups = [cpu_time / t for t in df['Time_ms']]\n",
                "    axes[1].bar(df['Version'], speedups, color=colors)\n",
                "    axes[1].set_ylabel('Speedup')\n",
                "    axes[1].set_title('GPU Speedup vs CPU')\n",
                "    axes[1].axhline(y=20, color='red', linestyle='--', alpha=0.7, label='Target (20x)')\n",
                "    axes[1].legend()\n",
                "    for i, s in enumerate(speedups):\n",
                "        axes[1].text(i, s + max(speedups)*0.02, f'{s:.0f}x', ha='center', fontsize=9)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Run benchmark first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 4: Lessons Learned\n",
                "\n",
                "## 4.1 Key Technical Insights\n",
                "\n",
                "**CUDA Programming:**\n",
                "- Memory coalescing is critical: NCHW layout ensures consecutive threads access consecutive addresses\n",
                "- Warp shuffle (`__shfl_down_sync`) avoids shared memory latency for reductions\n",
                "- cuBLAS achieves near-peak performance through optimized register blocking\n",
                "\n",
                "**Deep Learning:**\n",
                "- He initialization (`std = sqrt(2/fan_in)`) prevents gradient explosion in ReLU networks\n",
                "- Gradient clipping stabilizes training for deep networks\n",
                "- Autoencoder features capture visual patterns but have limited discriminative power vs supervised learning\n",
                "\n",
                "**Performance Optimization:**\n",
                "- Naive GPU kernels are memory-bandwidth bound, not compute-bound\n",
                "- im2col + GEMM provides the largest speedup by leveraging vendor-optimized libraries\n",
                "- Profile-guided optimization is essential; assumptions about bottlenecks are often wrong\n",
                "\n",
                "## 4.2 Major Challenges and Solutions\n",
                "\n",
                "| Challenge | Problem | Solution |\n",
                "|-----------|---------|----------|\n",
                "| Gradient Explosion | Training loss became NaN | He initialization + gradient clipping (max_norm=1.0) |\n",
                "| Memory Bandwidth | Naive kernel ~10% peak FLOPS | im2col transformation + cuBLAS SGEMM |\n",
                "| SVM Memory | ThunderSVM OOM on 60K samples | High RAM mode (~17GB peak) |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 5: Conclusion\n",
                "\n",
                "## 5.1 Project Summary\n",
                "\n",
                "| Metric | Target | Achieved | Status |\n",
                "|--------|--------|----------|--------|\n",
                "| Training time | < 10 min | ~51s/epoch | ✅ Exceeded |\n",
                "| GPU speedup | > 20× | 1690× | ✅ Exceeded |\n",
                "| Test accuracy | 60-65% | 65% | ✅ Met |\n",
                "| Feature extraction | < 20s | ~7.6s | ✅ Met |\n",
                "\n",
                "## 5.2 Key Achievements\n",
                "\n",
                "| Achievement | Value |\n",
                "|-------------|-------|\n",
                "| Maximum speedup | 1690× (GPU-v2 vs CPU) |\n",
                "| Best optimization | im2col + cuBLAS GEMM |\n",
                "| Classification accuracy | 65% on CIFAR-10 |\n",
                "| Skills mastered | CUDA kernels, cuBLAS, memory optimization |\n",
                "\n",
                "## 5.3 Limitations\n",
                "\n",
                "- 65% accuracy is lower than supervised CNN (~96%)\n",
                "- SVM requires high RAM (~17GB)\n",
                "- No multi-GPU support\n",
                "- Fixed batch size (not auto-tuned)\n",
                "\n",
                "## 5.4 Future Work\n",
                "\n",
                "**Performance:** Winograd convolution, multi-stream training, FP16 mixed precision\n",
                "\n",
                "**Accuracy:** VAE for better latent structure, supervised fine-tuning, alternative classifiers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Appendix A: Project Structure\n",
                "\n",
                "```\n",
                "AutoEncoder-CUDA/\n",
                "├── checkpoints/          # Model weights\n",
                "│   ├── encoder.weights   # Pretrained encoder\n",
                "│   └── svm.bin           # Pretrained SVM\n",
                "├── data/                 # CIFAR-10 binary files\n",
                "├── docs/                 # Documentation\n",
                "├── external/             # ThunderSVM\n",
                "├── notebooks/            # This notebook\n",
                "├── scripts/              # Utility scripts\n",
                "│   ├── benchmark.sh\n",
                "│   ├── download_cifar10.sh\n",
                "│   └── download_weights.sh\n",
                "└── src/\n",
                "    ├── cpu/              # CPU baseline\n",
                "    └── gpu/              # CUDA implementation\n",
                "        ├── kernels/      # CUDA kernels\n",
                "        │   ├── forward/\n",
                "        │   ├── backward/\n",
                "        │   └── gemm/     # im2col + GEMM\n",
                "        └── svm/          # SVM wrapper\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Appendix B: Usage Reference\n",
                "\n",
                "```bash\n",
                "# Commands\n",
                "./run.sh train-autoencoder   # Train autoencoder only\n",
                "./run.sh train-svm           # Train SVM with existing encoder\n",
                "./run.sh evaluate            # Evaluate with pretrained weights\n",
                "./run.sh pipeline            # Full: train -> SVM -> evaluate\n",
                "\n",
                "# Options\n",
                "--device cpu|gpu             # Device (default: gpu)\n",
                "--version naive|v1|v2        # GPU version (default: v2)\n",
                "--epochs N                   # Training epochs (default: 20)\n",
                "--samples N                  # Limit samples (0=all)\n",
                "\n",
                "# Examples\n",
                "./run.sh train-autoencoder --epochs 5 --samples 1000   # Quick test\n",
                "./run.sh pipeline --epochs 20                          # Full training\n",
                "```\n",
                "\n",
                "---\n",
                "**End of Report**"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
